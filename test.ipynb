{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import alphalens as al\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import baostock as bs\n",
    "%matplotlib inline\n",
    "\n",
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IC回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换股票代码格式的函数\n",
    "def convert_code(code):\n",
    "    if code.endswith('.XSHG'):\n",
    "        return 'sh.' + code[:6]\n",
    "    elif code.endswith('.XSHE'):\n",
    "        return 'sz.' + code[:6]\n",
    "    else:\n",
    "        return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 factor\n",
      "timestamp           asset              \n",
      "2023-06-07 10:00:00 sz.000001 -0.262344\n",
      "                    sz.000002  0.297081\n",
      "                    sz.000004  0.530078\n",
      "                    sz.000005  0.034260\n",
      "                    sz.000006 -0.613651\n",
      "...                                 ...\n",
      "2023-08-17 13:30:00 sz.000028 -0.051398\n",
      "                    sz.000029 -1.083397\n",
      "                    sz.000030  1.767867\n",
      "                    sz.000031  0.623799\n",
      "                    sz.000032 -2.315532\n",
      "\n",
      "[2600 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 读取因子数据\n",
    "factor_data = pd.read_csv('factor.csv')\n",
    "\n",
    "# 合并日期和时间列为一个新的时间戳列\n",
    "factor_data['timestamp'] = pd.to_datetime(factor_data['date'] + ' ' + factor_data['time'])\n",
    "\n",
    "# 设置新的时间戳列为索引\n",
    "factor_data.set_index('timestamp', inplace=True)\n",
    "\n",
    "# 删除原始的日期和时间列\n",
    "factor_data.drop(['date', 'time'], axis=1, inplace=True)\n",
    "\n",
    "# 转换股票代码格式并转换因子数据格式为长格式\n",
    "factor_data.columns = [convert_code(col) for col in factor_data.columns]\n",
    "factor_data = factor_data.stack()\n",
    "factor_data.index = factor_data.index.set_names(['timestamp', 'asset'])\n",
    "factor_data = factor_data.reset_index()\n",
    "factor_data.columns = ['timestamp', 'asset', 'factor']\n",
    "\n",
    "# 确保索引是MultiIndex\n",
    "factor_data.set_index(['timestamp', 'asset'], inplace=True)\n",
    "\n",
    "print(factor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载更新数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "logout success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baostock.data.resultset.ResultData at 0x28b5630e130>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取因子数据\n",
    "factor_data = pd.read_csv('factor.csv')\n",
    "factor_data['timestamp'] = pd.to_datetime(factor_data['date'] + ' ' + factor_data['time'])\n",
    "factor_data.set_index('timestamp', inplace=True)\n",
    "\n",
    "# 提取所有股票代码并转换格式\n",
    "stock_codes = [convert_code(code) for code in factor_data.columns[2:]]\n",
    "\n",
    "# 提取日期范围\n",
    "start_date = factor_data.index.min().strftime('%Y-%m-%d')\n",
    "end_date = factor_data.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "# 登录baostock\n",
    "bs.login()\n",
    "\n",
    "# 遍历所有股票代码并下载数据\n",
    "for stock_code in stock_codes:\n",
    "    data_list = []\n",
    "    rs = bs.query_history_k_data_plus(stock_code,\n",
    "                                      \"date,time,code,open,high,low,close,volume,amount,adjustflag\",\n",
    "                                      start_date=start_date, end_date=end_date,\n",
    "                                      frequency=\"30\", adjustflag=\"3\")\n",
    "    while (rs.error_code == '0') & rs.next():\n",
    "        row_data=rs.get_row_data()\n",
    "        if row_data[1].endswith('100000000') or row_data[1].endswith('133000000'):\n",
    "            data_list.append(row_data)\n",
    "\n",
    "    # 转换为DataFrame并保存\n",
    "    data_df = pd.DataFrame(data_list, columns=rs.fields)\n",
    "    data_df.to_csv(f'C:/LIFT/price_data/{stock_code}.csv', index=False)\n",
    "\n",
    "# 登出系统\n",
    "bs.logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并价格数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设所有价格数据文件都存储在这个目录下\n",
    "price_data_directory = 'C:/LIFT/price_data/'\n",
    "\n",
    "# 初始化空的DataFrame来存储所有股票的价格数据\n",
    "all_prices = pd.DataFrame()\n",
    "\n",
    "# 遍历目录中的每个文件\n",
    "for filename in os.listdir(price_data_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # 读取股票价格数据\n",
    "        stock_price_data = pd.read_csv(os.path.join(price_data_directory, filename))\n",
    "\n",
    "        # 处理日期和时间格式\n",
    "        stock_price_data['date'] = pd.to_datetime(stock_price_data['date'], format='%Y-%m-%d')\n",
    "        stock_price_data['time'] = stock_price_data['time'].astype(str).str.zfill(17)\n",
    "        stock_price_data['time'] = pd.to_datetime(stock_price_data['time'], format='%Y%m%d%H%M%S%f').dt.time\n",
    "\n",
    "        # 合并日期和时间为一个完整的timestamp\n",
    "        stock_price_data['timestamp'] = pd.to_datetime(stock_price_data['date'].astype(str) + ' ' + stock_price_data['time'].astype(str))\n",
    "\n",
    "        # 设置timestamp为索引\n",
    "        stock_price_data.set_index('timestamp', inplace=True)\n",
    "\n",
    "        # 提取收盘价并添加到主DataFrame\n",
    "        all_prices[filename.rstrip('.csv')] = stock_price_data['close']\n",
    "\n",
    "# 确保索引是日期时间戳\n",
    "all_prices.index = pd.to_datetime(all_prices.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 stack 方法将 all_prices 转换为 MultiIndex Series\n",
    "stacked_prices = all_prices.stack()\n",
    "\n",
    "# 重新设置索引名称\n",
    "stacked_prices.index.set_names(['timestamp', 'asset'], inplace=True)\n",
    "\n",
    "# 给Series命名\n",
    "stacked_prices.name = 'price'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp            asset    \n",
      "2023-06-07 10:00:00  sz.000001    11.98\n",
      "                     sz.000002    14.59\n",
      "                     sz.000004    15.28\n",
      "                     sz.000005     1.17\n",
      "                     sz.000006     4.75\n",
      "                                  ...  \n",
      "2023-08-17 13:30:00  sz.000028     33.8\n",
      "                     sz.000029    12.58\n",
      "                     sz.000030     5.27\n",
      "                     sz.000031     4.23\n",
      "                     sz.000032    29.42\n",
      "Name: price, Length: 2598, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(stacked_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     sz.000001  sz.000002  sz.000004  sz.000005  sz.000006  \\\n",
      "timestamp                                                                    \n",
      "2023-06-07 10:00:00      11.98      14.59      15.28       1.17       4.75   \n",
      "2023-06-07 13:30:00      11.96      14.66      15.96       1.17       4.77   \n",
      "2023-06-08 10:00:00      11.92      14.49      15.42       1.19       4.76   \n",
      "2023-06-08 13:30:00      12.08      14.83      15.09       1.21       4.85   \n",
      "2023-06-09 10:00:00      11.93      14.63      15.26       1.18       4.78   \n",
      "\n",
      "                     sz.000007  sz.000008  sz.000009  sz.000010  sz.000011  \\\n",
      "timestamp                                                                    \n",
      "2023-06-07 10:00:00       3.64       2.36      11.86       2.25       9.69   \n",
      "2023-06-07 13:30:00       3.76       2.38      11.73       2.27       9.69   \n",
      "2023-06-08 10:00:00       3.76       2.36      11.76       2.25       9.75   \n",
      "2023-06-08 13:30:00       3.84       2.36      11.70       2.28       9.91   \n",
      "2023-06-09 10:00:00       3.83       2.37      11.73       2.25       9.72   \n",
      "\n",
      "                     ...  sz.000024  sz.000025  sz.000026  sz.000027  \\\n",
      "timestamp            ...                                               \n",
      "2023-06-07 10:00:00  ...        NaN      16.84      12.26       6.61   \n",
      "2023-06-07 13:30:00  ...        NaN      16.90      12.32       6.69   \n",
      "2023-06-08 10:00:00  ...        NaN      16.65      12.21       6.58   \n",
      "2023-06-08 13:30:00  ...        NaN      17.26      12.19       6.66   \n",
      "2023-06-09 10:00:00  ...        NaN      17.49      12.28       6.70   \n",
      "\n",
      "                    sz.000028  sz.000029  sz.000030  sz.000031 sz.000032  \\\n",
      "timestamp                                                                  \n",
      "2023-06-07 10:00:00     42.95      11.86       4.76       3.79     33.80   \n",
      "2023-06-07 13:30:00     43.28      11.85       4.72       3.83     34.14   \n",
      "2023-06-08 10:00:00     42.62      11.81       4.68       3.85     33.50   \n",
      "2023-06-08 13:30:00     42.06      11.99       4.71       3.90     33.34   \n",
      "2023-06-09 10:00:00     42.12      11.72       4.80       3.88     34.08   \n",
      "\n",
      "                     sz.000033  \n",
      "timestamp                       \n",
      "2023-06-07 10:00:00        NaN  \n",
      "2023-06-07 13:30:00        NaN  \n",
      "2023-06-08 10:00:00        NaN  \n",
      "2023-06-08 13:30:00        NaN  \n",
      "2023-06-09 10:00:00        NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "                           date      time  000001.XSHE  000002.XSHE  \\\n",
      "timestamp                                                             \n",
      "2023-06-07 10:00:00  2023-06-07  10:00:00    -0.262344     0.297081   \n",
      "2023-06-07 13:30:00  2023-06-07  13:30:00    -0.281437     0.607447   \n",
      "2023-06-08 10:00:00  2023-06-08  10:00:00    -0.118193     0.028924   \n",
      "2023-06-08 13:30:00  2023-06-08  13:30:00    -0.269880     0.656808   \n",
      "2023-06-09 10:00:00  2023-06-09  10:00:00    -0.086187     0.350192   \n",
      "\n",
      "                     000004.XSHE  000005.XSHE  000006.XSHE  000007.XSHE  \\\n",
      "timestamp                                                                 \n",
      "2023-06-07 10:00:00     0.530078     0.034260    -0.613651    -0.000418   \n",
      "2023-06-07 13:30:00     0.711018     0.048785    -0.739596    -0.029462   \n",
      "2023-06-08 10:00:00     0.510999     0.004376    -0.511037    -0.029902   \n",
      "2023-06-08 13:30:00     0.668644     0.051294    -0.652145    -0.043614   \n",
      "2023-06-09 10:00:00     0.032983     0.002621    -0.226345    -0.023445   \n",
      "\n",
      "                     000008.XSHE  000009.XSHE  ...  000024.XSHE  000025.XSHE  \\\n",
      "timestamp                                      ...                             \n",
      "2023-06-07 10:00:00     0.372981     0.309491  ...          NaN    -0.579783   \n",
      "2023-06-07 13:30:00     1.679690     0.702172  ...          NaN    -1.478011   \n",
      "2023-06-08 10:00:00     0.004062     0.088675  ...          NaN    -0.723863   \n",
      "2023-06-08 13:30:00     1.678538     0.719343  ...          NaN    -1.370420   \n",
      "2023-06-09 10:00:00     0.520461     0.189789  ...          NaN    -0.348044   \n",
      "\n",
      "                     000026.XSHE  000027.XSHE  000028.XSHE  000029.XSHE  \\\n",
      "timestamp                                                                 \n",
      "2023-06-07 10:00:00    -0.035755     0.982627     0.041336    -1.192251   \n",
      "2023-06-07 13:30:00    -0.127182     1.479160     0.273109    -1.494053   \n",
      "2023-06-08 10:00:00    -0.015849     1.398903     0.077360    -1.197070   \n",
      "2023-06-08 13:30:00    -0.059420     1.506045     0.254420    -1.478233   \n",
      "2023-06-09 10:00:00     0.028524     1.078861     0.267994    -1.205539   \n",
      "\n",
      "                     000030.XSHE  000031.XSHE  000032.XSHE  000033.XSHE  \n",
      "timestamp                                                                \n",
      "2023-06-07 10:00:00     1.287807     0.415260    -0.156003          NaN  \n",
      "2023-06-07 13:30:00     1.604959     0.633838    -2.155920          NaN  \n",
      "2023-06-08 10:00:00     0.465835     0.419648    -1.840789          NaN  \n",
      "2023-06-08 13:30:00     1.582471     0.645589    -2.157412          NaN  \n",
      "2023-06-09 10:00:00     0.064889     0.552781    -1.042433          NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_prices.head())\n",
    "print(factor_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为 factor_data 提取时间\n",
    "timestamps_factor = factor_data.index.get_level_values('timestamp')\n",
    "times_factor = pd.to_datetime(timestamps_factor).time\n",
    "\n",
    "# 为 stacked_prices 提取时间\n",
    "timestamps_prices = stacked_prices.index.get_level_values('timestamp')\n",
    "times_prices = pd.to_datetime(timestamps_prices).time\n",
    "\n",
    "# 提取上午10:00的因子数据\n",
    "factor_data_am = factor_data[times_factor == pd.Timestamp('10:00:00').time()]\n",
    "\n",
    "# 提取上午10:00的价格数据\n",
    "stacked_prices_am = stacked_prices[times_prices == pd.Timestamp('10:00:00').time()]\n",
    "\n",
    "# 提取下午13:30的因子数据\n",
    "factor_data_pm = factor_data[times_factor == pd.Timestamp('13:30:00').time()]\n",
    "\n",
    "# 提取下午13:30的价格数据\n",
    "stacked_prices_pm = stacked_prices[times_prices == pd.Timestamp('13:30:00').time()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiIndex' object has no attribute 'tz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 准备Alphalens的因子数据\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[43mal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_clean_factor_and_forward_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfactor_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfactor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mprices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacked_prices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mperiods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 使用Alphalens生成回测分析报告\u001b[39;00m\n\u001b[0;32m      8\u001b[0m al\u001b[38;5;241m.\u001b[39mtears\u001b[38;5;241m.\u001b[39mcreate_returns_tear_sheet(test_result, long_short\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, group_neutral\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, by_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy\\.conda\\envs\\py38\\lib\\site-packages\\alphalens\\utils.py:827\u001b[0m, in \u001b[0;36mget_clean_factor_and_forward_returns\u001b[1;34m(factor, prices, groupby, binning_by_group, quantiles, bins, periods, filter_zscore, groupby_labels, max_loss, zero_aware, cumulative_returns)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=665'>666</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_clean_factor_and_forward_returns\u001b[39m(factor,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=666'>667</a>\u001b[0m                                          prices,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=667'>668</a>\u001b[0m                                          groupby\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=675'>676</a>\u001b[0m                                          zero_aware\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=676'>677</a>\u001b[0m                                          cumulative_returns\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=677'>678</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=678'>679</a>\u001b[0m \u001b[39m    Formats the factor data, pricing data, and group mappings into a DataFrame\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=679'>680</a>\u001b[0m \u001b[39m    that contains aligned MultiIndex indices of timestamp and asset. The\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=824'>825</a>\u001b[0m \u001b[39m        For use when forward returns are already available.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=825'>826</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=826'>827</a>\u001b[0m     forward_returns \u001b[39m=\u001b[39m compute_forward_returns(\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=827'>828</a>\u001b[0m         factor,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=828'>829</a>\u001b[0m         prices,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=829'>830</a>\u001b[0m         periods,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=830'>831</a>\u001b[0m         filter_zscore,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=831'>832</a>\u001b[0m         cumulative_returns,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=832'>833</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=834'>835</a>\u001b[0m     factor_data \u001b[39m=\u001b[39m get_clean_factor(factor, forward_returns, groupby\u001b[39m=\u001b[39mgroupby,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=835'>836</a>\u001b[0m                                    groupby_labels\u001b[39m=\u001b[39mgroupby_labels,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=836'>837</a>\u001b[0m                                    quantiles\u001b[39m=\u001b[39mquantiles, bins\u001b[39m=\u001b[39mbins,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=837'>838</a>\u001b[0m                                    binning_by_group\u001b[39m=\u001b[39mbinning_by_group,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=838'>839</a>\u001b[0m                                    max_loss\u001b[39m=\u001b[39mmax_loss, zero_aware\u001b[39m=\u001b[39mzero_aware)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=840'>841</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m factor_data\n",
      "File \u001b[1;32mc:\\Users\\Jimmy\\.conda\\envs\\py38\\lib\\site-packages\\alphalens\\utils.py:263\u001b[0m, in \u001b[0;36mcompute_forward_returns\u001b[1;34m(factor, prices, periods, filter_zscore, cumulative_returns)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=220'>221</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=221'>222</a>\u001b[0m \u001b[39mFinds the N period forward returns (as percent change) for each asset\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=222'>223</a>\u001b[0m \u001b[39mprovided.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=258'>259</a>\u001b[0m \u001b[39m    from the input data (see infer_trading_calendar for more details).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=259'>260</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=261'>262</a>\u001b[0m factor_dateindex \u001b[39m=\u001b[39m factor\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mlevels[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=262'>263</a>\u001b[0m \u001b[39mif\u001b[39;00m factor_dateindex\u001b[39m.\u001b[39mtz \u001b[39m!=\u001b[39m prices\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mtz:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=263'>264</a>\u001b[0m     \u001b[39mraise\u001b[39;00m NonMatchingTimezoneError(\u001b[39m\"\u001b[39m\u001b[39mThe timezone of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfactor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=264'>265</a>\u001b[0m                                    \u001b[39m\"\u001b[39m\u001b[39msame as the timezone of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprices\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=265'>266</a>\u001b[0m                                    \u001b[39m\"\u001b[39m\u001b[39mthe pandas methods tz_localize and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=266'>267</a>\u001b[0m                                    \u001b[39m\"\u001b[39m\u001b[39mtz_convert.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jimmy/.conda/envs/py38/lib/site-packages/alphalens/utils.py?line=268'>269</a>\u001b[0m freq \u001b[39m=\u001b[39m infer_trading_calendar(factor_dateindex, prices\u001b[39m.\u001b[39mindex)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultiIndex' object has no attribute 'tz'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa8fb4ab092f918385b1a61a5dbd2cab5ddd3b84cec1c64fc768df142641adc7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
